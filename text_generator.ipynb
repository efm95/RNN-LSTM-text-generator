{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1039,"status":"ok","timestamp":1661348559209,"user":{"displayName":"Edoardo Filippi-Mazzola","userId":"12937409144207641672"},"user_tz":-120},"id":"cU6qwSwSkGJe","outputId":"5e9917a1-c641-4186-e712-018ccd4f001d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Wed Aug 24 13:42:37 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   70C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3057,"status":"ok","timestamp":1661348562264,"user":{"displayName":"Edoardo Filippi-Mazzola","userId":"12937409144207641672"},"user_tz":-120},"id":"zVdAKEIulHUo","outputId":"5848c1b2-a7ef-4f74-9c77-8c34199d4058"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"uIH7JHid-EYe"},"source":["# Aesop's fables\n","\n","Using Aesop's fables as a training set to generate text. "]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2596,"status":"ok","timestamp":1661348564855,"user":{"displayName":"Edoardo Filippi-Mazzola","userId":"12937409144207641672"},"user_tz":-120},"id":"OTQcW1Qfl1yv","outputId":"1557a1fe-0ea1-4f6c-c8d8-06f72636d10c"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2022-08-24 13:42:41--  http://www.gutenberg.org/files/49010/49010-0.txt\n","Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n","Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:80... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://www.gutenberg.org/files/49010/49010-0.txt [following]\n","--2022-08-24 13:42:42--  https://www.gutenberg.org/files/49010/49010-0.txt\n","Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 185303 (181K) [text/plain]\n","Saving to: ‘49010-0.txt’\n","\n","49010-0.txt         100%[===================>] 180.96K   235KB/s    in 0.8s    \n","\n","2022-08-24 13:42:44 (235 KB/s) - ‘49010-0.txt’ saved [185303/185303]\n","\n"]}],"source":["!wget http://www.gutenberg.org/files/49010/49010-0.txt\n","text_path = \"49010-0.txt\""]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":669,"status":"ok","timestamp":1661348565520,"user":{"displayName":"Edoardo Filippi-Mazzola","userId":"12937409144207641672"},"user_tz":-120},"id":"XQdEreexl9J8"},"outputs":[],"source":["import torch\n","import numpy as np\n","import model\n","from tokenizer import *\n","from trainer import *"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1954,"status":"ok","timestamp":1661348568704,"user":{"displayName":"Edoardo Filippi-Mazzola","userId":"12937409144207641672"},"user_tz":-120},"id":"sE5da9KEmXRs","outputId":"e98a7e16-9da6-4b3b-9da8-453827cfcc6a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Reading text file from: 49010-0.txt\n","Done.\n"]}],"source":["batch_size = 32\n","bptt_len = 64\n","\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","my_data = LongTextData(text_path, device=DEVICE)\n","batches = ChunkedTextData(my_data, batch_size, bptt_len, pad_id=0)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1661348568704,"user":{"displayName":"Edoardo Filippi-Mazzola","userId":"12937409144207641672"},"user_tz":-120},"id":"uSXMe-9cmxVg","outputId":"0e09a848-597c-4e64-93fb-501288da4395"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([64, 32])\n"]},{"data":{"text/plain":["tensor([ 0,  2,  3,  4,  5,  6,  7,  8,  9, 10,  5, 11, 12,  6, 13, 14, 12,  5,\n","        15, 16,  5,  8, 17,  6, 18, 19,  9,  9, 20,  6,  9, 21,  6, 22,  5, 23,\n","         9, 24, 25, 23,  6, 26, 27, 16, 28,  5, 23, 29,  6, 16, 30,  6, 31, 32,\n","         6, 33, 32,  6, 34, 12, 35, 11, 20, 15], device='cuda:0')"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# input to the network\n","print(batches[0][:-1].shape)\n","batches[0][:-1, 0]"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1661348568704,"user":{"displayName":"Edoardo Filippi-Mazzola","userId":"12937409144207641672"},"user_tz":-120},"id":"W-B2PaV4m0WZ","outputId":"3403e997-678f-41f4-d231-1fae33cf10c9"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([64, 32])\n"]},{"data":{"text/plain":["tensor([ 2,  3,  4,  5,  6,  7,  8,  9, 10,  5, 11, 12,  6, 13, 14, 12,  5, 15,\n","        16,  5,  8, 17,  6, 18, 19,  9,  9, 20,  6,  9, 21,  6, 22,  5, 23,  9,\n","        24, 25, 23,  6, 26, 27, 16, 28,  5, 23, 29,  6, 16, 30,  6, 31, 32,  6,\n","        33, 32,  6, 34, 12, 35, 11, 20, 15,  5], device='cuda:0')"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# target tokens to be predicted\n","print(batches[0][1:].shape)\n","batches[0][1:, 0]"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1661348568705,"user":{"displayName":"Edoardo Filippi-Mazzola","userId":"12937409144207641672"},"user_tz":-120},"id":"2ar6ete3nMhM"},"outputs":[],"source":["vocab_size = len(my_data.vocab.id_to_string)\n","lstm_size = 2048\n","embedding_size = 64"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1661348568705,"user":{"displayName":"Edoardo Filippi-Mazzola","userId":"12937409144207641672"},"user_tz":-120},"id":"9SR3zIeBjUfW"},"outputs":[],"source":["net = model.RNN(vocab_size = vocab_size,\n","                                batch_size = batch_size,\n","                                lstm_size = lstm_size,\n","                                embedding_size = embedding_size)"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":2046,"status":"ok","timestamp":1661348570746,"user":{"displayName":"Edoardo Filippi-Mazzola","userId":"12937409144207641672"},"user_tz":-120},"id":"6bdBikmbmPz3"},"outputs":[],"source":["train = trainer(model=net,\n","                dictionary = my_data)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":502898,"status":"ok","timestamp":1661349073641,"user":{"displayName":"Edoardo Filippi-Mazzola","userId":"12937409144207641672"},"user_tz":-120},"id":"gQ84UOeggV8W","outputId":"e2d0a2d9-3641-4591-e879-9ae94caa7f29"},"outputs":[{"name":"stderr","output_type":"stream","text":["/content/drive/MyDrive/RNN/trainer.py:65: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n","  nn.utils.clip_grad_norm(self.model.parameters(),self.clip)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 1 | Loss: 7.139899253845215| Perplexity: 1261.30126953125\n","Epoch: 2 | Loss: 5.156662464141846| Perplexity: 173.58413696289062\n","Epoch: 3 | Loss: 4.427094459533691| Perplexity: 83.68790435791016\n","Epoch: 4 | Loss: 3.9301908016204834| Perplexity: 50.916690826416016\n","Epoch: 5 | Loss: 3.5348916053771973| Perplexity: 34.291297912597656\n","Epoch: 6 | Loss: 3.18271541595459| Perplexity: 24.112138748168945\n","Epoch: 7 | Loss: 2.845998764038086| Perplexity: 17.218748092651367\n","Epoch: 8 | Loss: 2.5455780029296875| Perplexity: 12.750596046447754\n","Epoch: 9 | Loss: 2.2380754947662354| Perplexity: 9.37527084350586\n","Epoch: 10 | Loss: 1.9450398683547974| Perplexity: 6.993911266326904\n","Epoch: 11 | Loss: 1.6716183423995972| Perplexity: 5.320771217346191\n","Epoch: 12 | Loss: 1.3822375535964966| Perplexity: 3.9838054180145264\n","Epoch: 13 | Loss: 1.1365567445755005| Perplexity: 3.116020679473877\n","Epoch: 14 | Loss: 0.9554245471954346| Perplexity: 2.599774122238159\n","Epoch: 15 | Loss: 0.7941458821296692| Perplexity: 2.212550401687622\n","Epoch: 16 | Loss: 0.6578207612037659| Perplexity: 1.930580496788025\n","Epoch: 17 | Loss: 0.5373135805130005| Perplexity: 1.7114031314849854\n","Epoch: 18 | Loss: 0.44128310680389404| Perplexity: 1.5547007322311401\n","Epoch: 19 | Loss: 0.37561115622520447| Perplexity: 1.455880880355835\n","Epoch: 20 | Loss: 0.31908220052719116| Perplexity: 1.3758643865585327\n","Epoch: 21 | Loss: 0.2802034616470337| Perplexity: 1.3233990669250488\n","Epoch: 22 | Loss: 0.23798485100269318| Perplexity: 1.2686899900436401\n","Epoch: 23 | Loss: 0.21134062111377716| Perplexity: 1.2353330850601196\n","Epoch: 24 | Loss: 0.18323037028312683| Perplexity: 1.2010910511016846\n","Epoch: 25 | Loss: 0.1599201112985611| Perplexity: 1.173417091369629\n","Epoch: 26 | Loss: 0.14126871526241302| Perplexity: 1.1517341136932373\n","Epoch: 27 | Loss: 0.13126486539840698| Perplexity: 1.1402697563171387\n","Epoch: 28 | Loss: 0.11760230362415314| Perplexity: 1.124796748161316\n","Epoch: 29 | Loss: 0.10253380239009857| Perplexity: 1.107974648475647\n","Epoch: 30 | Loss: 0.09514065086841583| Perplexity: 1.099813461303711\n","Epoch: 31 | Loss: 0.08578787744045258| Perplexity: 1.089575171470642\n","Epoch: 32 | Loss: 0.0802069902420044| Perplexity: 1.0835113525390625\n","Epoch: 33 | Loss: 0.07200014591217041| Perplexity: 1.074655532836914\n","Epoch: 34 | Loss: 0.06598801910877228| Perplexity: 1.068213939666748\n","Epoch: 35 | Loss: 0.05899663269519806| Perplexity: 1.0607717037200928\n","Epoch: 36 | Loss: 0.053277838975191116| Perplexity: 1.0547226667404175\n","Epoch: 37 | Loss: 0.04842580109834671| Perplexity: 1.0496174097061157\n","Epoch: 38 | Loss: 0.04403448477387428| Perplexity: 1.0450184345245361\n","Epoch: 39 | Loss: 0.03894218057394028| Perplexity: 1.0397104024887085\n","Epoch: 40 | Loss: 0.036971691995859146| Perplexity: 1.0376635789871216\n","Epoch: 41 | Loss: 0.03290059417486191| Perplexity: 1.0334477424621582\n","Epoch: 42 | Loss: 0.032584842294454575| Perplexity: 1.0331215858459473\n","Epoch: 43 | Loss: 0.03356359153985977| Perplexity: 1.0341331958770752\n","Epoch: 44 | Loss: 0.03751929849386215| Perplexity: 1.0382320880889893\n","Epoch: 45 | Loss: 0.04330859333276749| Perplexity: 1.0442601442337036\n","Epoch: 46 | Loss: 0.08524898439645767| Perplexity: 1.088988184928894\n","Epoch: 47 | Loss: 0.8544327616691589| Perplexity: 2.350040912628174\n","Epoch: 48 | Loss: 1.460681676864624| Perplexity: 4.308896064758301\n","Epoch: 49 | Loss: 0.8491039872169495| Perplexity: 2.3375515937805176\n","Epoch: 50 | Loss: 0.4773613214492798| Perplexity: 1.6118156909942627\n","Epoch: 51 | Loss: 0.2675332725048065| Perplexity: 1.3067371845245361\n","Epoch: 52 | Loss: 0.16108766198158264| Perplexity: 1.1747878789901733\n","Epoch: 53 | Loss: 0.0911373719573021| Perplexity: 1.0954195261001587\n","Epoch: 54 | Loss: 0.05283607169985771| Perplexity: 1.054256796836853\n","Epoch: 55 | Loss: 0.031934697180986404| Perplexity: 1.0324500799179077\n","Epoch: 56 | Loss: 0.021025391295552254| Perplexity: 1.0212479829788208\n","Perplexity below 1.03\n","Epoch: 57 | Loss: 0.015549651347100735| Perplexity: 1.0156711339950562\n","Perplexity below 1.03\n","Epoch: 58 | Loss: 0.012108320370316505| Perplexity: 1.0121818780899048\n","Perplexity below 1.03\n","Perplexity below 1.03 for more then 3 iterations -- STOPPING ITERATIONS\n","SAVING MODEL\n"]},{"data":{"text/plain":["([7.139899253845215,\n","  5.156662464141846,\n","  4.427094459533691,\n","  3.9301908016204834,\n","  3.5348916053771973,\n","  3.18271541595459,\n","  2.845998764038086,\n","  2.5455780029296875,\n","  2.2380754947662354,\n","  1.9450398683547974,\n","  1.6716183423995972,\n","  1.3822375535964966,\n","  1.1365567445755005,\n","  0.9554245471954346,\n","  0.7941458821296692,\n","  0.6578207612037659,\n","  0.5373135805130005,\n","  0.44128310680389404,\n","  0.37561115622520447,\n","  0.31908220052719116,\n","  0.2802034616470337,\n","  0.23798485100269318,\n","  0.21134062111377716,\n","  0.18323037028312683,\n","  0.1599201112985611,\n","  0.14126871526241302,\n","  0.13126486539840698,\n","  0.11760230362415314,\n","  0.10253380239009857,\n","  0.09514065086841583,\n","  0.08578787744045258,\n","  0.0802069902420044,\n","  0.07200014591217041,\n","  0.06598801910877228,\n","  0.05899663269519806,\n","  0.053277838975191116,\n","  0.04842580109834671,\n","  0.04403448477387428,\n","  0.03894218057394028,\n","  0.036971691995859146,\n","  0.03290059417486191,\n","  0.032584842294454575,\n","  0.03356359153985977,\n","  0.03751929849386215,\n","  0.04330859333276749,\n","  0.08524898439645767,\n","  0.8544327616691589,\n","  1.460681676864624,\n","  0.8491039872169495,\n","  0.4773613214492798,\n","  0.2675332725048065,\n","  0.16108766198158264,\n","  0.0911373719573021,\n","  0.05283607169985771,\n","  0.031934697180986404,\n","  0.021025391295552254,\n","  0.015549651347100735,\n","  0.012108320370316505],\n"," [1261.30126953125,\n","  173.58413696289062,\n","  83.68790435791016,\n","  50.916690826416016,\n","  34.291297912597656,\n","  24.112138748168945,\n","  17.218748092651367,\n","  12.750596046447754,\n","  9.37527084350586,\n","  6.993911266326904,\n","  5.320771217346191,\n","  3.9838054180145264,\n","  3.116020679473877,\n","  2.599774122238159,\n","  2.212550401687622,\n","  1.930580496788025,\n","  1.7114031314849854,\n","  1.5547007322311401,\n","  1.455880880355835,\n","  1.3758643865585327,\n","  1.3233990669250488,\n","  1.2686899900436401,\n","  1.2353330850601196,\n","  1.2010910511016846,\n","  1.173417091369629,\n","  1.1517341136932373,\n","  1.1402697563171387,\n","  1.124796748161316,\n","  1.107974648475647,\n","  1.099813461303711,\n","  1.089575171470642,\n","  1.0835113525390625,\n","  1.074655532836914,\n","  1.068213939666748,\n","  1.0607717037200928,\n","  1.0547226667404175,\n","  1.0496174097061157,\n","  1.0450184345245361,\n","  1.0397104024887085,\n","  1.0376635789871216,\n","  1.0334477424621582,\n","  1.0331215858459473,\n","  1.0341331958770752,\n","  1.0382320880889893,\n","  1.0442601442337036,\n","  1.088988184928894,\n","  2.350040912628174,\n","  4.308896064758301,\n","  2.3375515937805176,\n","  1.6118156909942627,\n","  1.3067371845245361,\n","  1.1747878789901733,\n","  1.0954195261001587,\n","  1.054256796836853,\n","  1.0324500799179077,\n","  1.0212479829788208,\n","  1.0156711339950562,\n","  1.0121818780899048])"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["train.fit(train_set=batches)"]},{"cell_type":"markdown","metadata":{},"source":["Generating text:"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1661349073642,"user":{"displayName":"Edoardo Filippi-Mazzola","userId":"12937409144207641672"},"user_tz":-120},"id":"PtcgXQHs6_-7","outputId":"4ce44d08-35c9-4a41-b6ec-d5e48eeb6172"},"outputs":[{"name":"stdout","output_type":"stream","text":["The when you have once\n","seen the city you will never be willing to return to this quiet place.”\n","\n","[Illustration]\n","\n","After being urged a long time, the Country Mouse at last agreed to go\n","to the city that very night. So they started off together, and about\n","midnight came to the great house where the City Mouse lived. In the\n","dining room was spread a rich feast; and the City Mouse, with many\n","airs and graces, ran about the table, and, picking out the nicest bits,\n","waited upon his country friend, who, amaze\n"]}],"source":["torch.manual_seed(10091995)\n","test = generate(net=net, tokenizer=my_data,size=500,beginning='The ')\n","print(''.join(test))"]},{"cell_type":"markdown","metadata":{"id":"px6tZR3l-AOm"},"source":["# Music lyrics"]},{"cell_type":"markdown","metadata":{},"source":["Using music lyrics from https://github.com/efm95/beatlestxt to train RNN. "]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":621,"status":"ok","timestamp":1661349074245,"user":{"displayName":"Edoardo Filippi-Mazzola","userId":"12937409144207641672"},"user_tz":-120},"id":"HDeGPr569_xL","outputId":"86154bda-3426-4040-a710-bc6dc2d5d0d5"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2022-08-24 13:51:13--  https://raw.githubusercontent.com/h4nkyn/beatlestxt/master/input.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2414861 (2.3M) [text/plain]\n","Saving to: ‘input.txt.1’\n","\n","input.txt.1         100%[===================>]   2.30M  --.-KB/s    in 0.04s   \n","\n","2022-08-24 13:51:13 (64.5 MB/s) - ‘input.txt.1’ saved [2414861/2414861]\n","\n"]}],"source":["!wget https://raw.githubusercontent.com/h4nkyn/beatlestxt/master/input.txt"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1720,"status":"ok","timestamp":1661349075963,"user":{"displayName":"Edoardo Filippi-Mazzola","userId":"12937409144207641672"},"user_tz":-120},"id":"LtZcL4GoAQzc","outputId":"e9e9caa2-0391-402a-aef5-6110cf057a3d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Reading text file from: input.txt\n","Done.\n"]}],"source":["text_path = 'input.txt'\n","batch_size = 256\n","bptt_len = 128\n","\n","my_data = LongTextData(text_path, device=DEVICE)\n","batches = ChunkedTextData(my_data, batch_size, bptt_len, pad_id=0)\n","\n","vocab_size = len(my_data.vocab.id_to_string)\n","lstm_size = 2048\n","embedding_size = 64"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1661349075963,"user":{"displayName":"Edoardo Filippi-Mazzola","userId":"12937409144207641672"},"user_tz":-120},"id":"yb9gDuatAYDy"},"outputs":[],"source":["net = model.RNN(vocab_size = vocab_size,\n","                                batch_size = batch_size,\n","                                lstm_size = lstm_size,\n","                                embedding_size = embedding_size)\n","\n","train = trainer(model=net,\n","                dictionary = my_data)"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1104764,"status":"ok","timestamp":1661350180725,"user":{"displayName":"Edoardo Filippi-Mazzola","userId":"12937409144207641672"},"user_tz":-120},"id":"ZmItYrtWAjp9","outputId":"e1b71a54-a98b-4705-f04c-52c8c3c4b296"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 1 | Loss: 0.7382544875144958| Perplexity: 2.092280149459839\n","Epoch: 2 | Loss: 0.4755738079547882| Perplexity: 1.6089372634887695\n","Epoch: 3 | Loss: 0.35672810673713684| Perplexity: 1.4286473989486694\n","Epoch: 4 | Loss: 0.2664473056793213| Perplexity: 1.305318832397461\n","Epoch: 5 | Loss: 0.19611157476902008| Perplexity: 1.2166626453399658\n","Epoch: 6 | Loss: 0.14327369630336761| Perplexity: 1.1540457010269165\n","Epoch: 7 | Loss: 0.10426858812570572| Perplexity: 1.1098984479904175\n","Epoch: 8 | Loss: 0.07408257573843002| Perplexity: 1.0768957138061523\n","Epoch: 9 | Loss: 0.051810186356306076| Perplexity: 1.0531758069992065\n","Epoch: 10 | Loss: 0.03591282293200493| Perplexity: 1.0365654230117798\n","Epoch: 11 | Loss: 0.024439994245767593| Perplexity: 1.0247410535812378\n","Perplexity below 1.03\n","Epoch: 12 | Loss: 0.016983237117528915| Perplexity: 1.0171282291412354\n","Perplexity below 1.03\n","Epoch: 13 | Loss: 0.012533707544207573| Perplexity: 1.0126125812530518\n","Perplexity below 1.03\n","Perplexity below 1.03 for more then 3 iterations -- STOPPING ITERATIONS\n","SAVING MODEL\n"]},{"data":{"text/plain":["([0.7382544875144958,\n","  0.4755738079547882,\n","  0.35672810673713684,\n","  0.2664473056793213,\n","  0.19611157476902008,\n","  0.14327369630336761,\n","  0.10426858812570572,\n","  0.07408257573843002,\n","  0.051810186356306076,\n","  0.03591282293200493,\n","  0.024439994245767593,\n","  0.016983237117528915,\n","  0.012533707544207573],\n"," [2.092280149459839,\n","  1.6089372634887695,\n","  1.4286473989486694,\n","  1.305318832397461,\n","  1.2166626453399658,\n","  1.1540457010269165,\n","  1.1098984479904175,\n","  1.0768957138061523,\n","  1.0531758069992065,\n","  1.0365654230117798,\n","  1.0247410535812378,\n","  1.0171282291412354,\n","  1.0126125812530518])"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["train.fit(train_set=batches)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1661350180725,"user":{"displayName":"Edoardo Filippi-Mazzola","userId":"12937409144207641672"},"user_tz":-120},"id":"xuiBcmIyAn-i","outputId":"ec4a5eef-e891-4a6d-bd05-60d675df33c4"},"outputs":[{"name":"stdout","output_type":"stream","text":["The that we are gonna get by,\n","So stop acting like a lady come and cry like baby on the outside.\n","On the outside\n","On the outside\n","\n","Misfits_EOT\n"," \n","You've been sleeping in a field but you look real rested\n","You set out to outrage but you can't get arrested\n","You say your image is new, but it looks well tested\n","You're lost without a crowd yet you go your own way\n","\n","You say your summer has gone\n","Now the winter is crawlin' in\n","They say that even in your day\n","Somehow you never could quite fit in\n","Though it's cold out\n"]}],"source":["torch.manual_seed(10091995)\n","test = generate(net=net, tokenizer=my_data,size=500,beginning='The ')\n","print(''.join(test))"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyN0yAhTXWBK0beWj/kQtRML","collapsed_sections":[],"name":"text_generator.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
